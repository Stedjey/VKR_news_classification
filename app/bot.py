import telebot
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import torch
import numpy as np
from scipy.special import softmax
import pickle
import sqlite3
from transformers import pipeline

# --- –°–æ–∑–¥–∞–Ω–∏–µ –ë–î –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –∑–∞–ø—É—Å–∫–µ ---
def create_db():
    conn = sqlite3.connect("bot_messages.db")
    cursor = conn.cursor()
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS messages (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            user_id INTEGER,
            username TEXT,
            text TEXT,
            predicted_category TEXT,
            confidence REAL,
            keywords TEXT,
            emotion TEXT,
            sentiment TEXT,
            timestamp DATETIME DEFAULT CURRENT_TIMESTAMP
        )
    ''')
    conn.commit()
    conn.close()

# –í—ã–∑–æ–≤ —Ñ—É–Ω–∫—Ü–∏–∏ —Å–æ–∑–¥–∞–Ω–∏—è –ë–î
create_db()

# --- –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –∏ —ç–Ω–∫–æ–¥–µ—Ä–∞ ---
model = AutoModelForSequenceClassification.from_pretrained("./rubert_final_model")
tokenizer = AutoTokenizer.from_pretrained("./rubert_final_model")

with open("rubert_label_encoder.pkl", "rb") as f:
    le = pickle.load(f)

# –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–π
sentiment_model = "sismetanin/rubert-ru-sentiment-rusentiment"
sentiment_analyzer = pipeline("sentiment-analysis", model=sentiment_model)

# –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —ç–º–æ—Ü–∏–π
emotion_model = pipeline(model="seara/rubert-tiny2-ru-go-emotions")
emotion_labels_map = {
    'admiration': '–≤–æ—Å—Ö–∏—â–µ–Ω–∏–µ', 'amusement': '–≤–µ—Å–µ–ª—å–µ', 'anger': '–∑–ª–æ—Å—Ç—å', 'annoyance': '—Ä–∞–∑–¥—Ä–∞–∂–µ–Ω–∏–µ',
    'approval': '–æ–¥–æ–±—Ä–µ–Ω–∏–µ', 'caring': '–∑–∞–±–æ—Ç–∞', 'confusion': '–Ω–µ–ø–æ–Ω–∏–º–∞–Ω–∏–µ', 'curiosity': '–ª—é–±–æ–ø—ã—Ç—Å—Ç–≤–æ',
    'desire': '–∂–µ–ª–∞–Ω–∏–µ', 'disappointment': '—Ä–∞–∑–æ—á–∞—Ä–æ–≤–∞–Ω–∏–µ', 'disapproval': '–Ω–µ–æ–¥–æ–±—Ä–µ–Ω–∏–µ', 'disgust': '–æ—Ç–≤—Ä–∞—â–µ–Ω–∏–µ',
    'embarrassment': '—Å–º—É—â–µ–Ω–∏–µ', 'excitement': '–≤–æ–∑–±—É–∂–¥–µ–Ω–∏–µ', 'fear': '—Å—Ç—Ä–∞—Ö', 'gratitude': '–ø—Ä–∏–∑–Ω–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å',
    'grief': '–≥–æ—Ä–µ', 'joy': '—Ä–∞–¥–æ—Å—Ç—å', 'love': '–ª—é–±–æ–≤—å', 'nervousness': '–Ω–µ—Ä–≤–æ–∑–Ω–æ—Å—Ç—å', 'optimism': '–æ–ø—Ç–∏–º–∏–∑–º',
    'pride': '–≥–æ—Ä–¥–æ—Å—Ç—å', 'realization': '–æ—Å–æ–∑–Ω–∞–Ω–∏–µ', 'relief': '–æ–±–ª–µ–≥—á–µ–Ω–∏–µ', 'remorse': '—Ä–∞—Å–∫–∞—è–Ω–∏–µ',
    'sadness': '–≥—Ä—É—Å—Ç—å', 'surprise': '—É–¥–∏–≤–ª–µ–Ω–∏–µ', 'neutral': '–Ω–µ–π—Ç—Ä–∞–ª—å–Ω–æ—Å—Ç—å'
}


# --- –§—É–Ω–∫—Ü–∏—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞ ---
def classify_text(text: str):
    # –û–±—Ä–µ–∑–∞–µ–º –≤—Ö–æ–¥–Ω–æ–π —Ç–µ–∫—Å—Ç –¥–æ 512 —Ç–æ–∫–µ–Ω–æ–≤
    inputs = tokenizer(text, return_tensors="pt", truncation=True, padding=True, max_length=512)
    with torch.no_grad():
        outputs = model(**inputs)
    logits = outputs.logits.detach().cpu().numpy()  # –ü–µ—Ä–µ–º–µ—â–∞–µ–º —Ç–µ–Ω–∑–æ—Ä –Ω–∞ CPU, –µ—Å–ª–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω GPU
    probs = softmax(logits, axis=1)
    # –ò–Ω–¥–µ–∫—Å –∫–ª–∞—Å—Å–∞ —Å –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å—é
    pred_idx = np.argmax(probs)
    # –ù–∞–∑–≤–∞–Ω–∏–µ –∫–ª–∞—Å—Å–∞
    class_name = le.inverse_transform([pred_idx])[0]
    # –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏
    confidence = probs[0][pred_idx]
    return class_name, confidence


# --- –§—É–Ω–∫—Ü–∏—è –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–π ---
def get_sentiment(text):
    sentiment = sentiment_analyzer(text, truncation=True, max_length=512)
    labels = {'LABEL_0': '–û—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω–æ–µ', 'LABEL_1': '–ù–µ–π—Ç—Ä–∞–ª—å–Ω–æ–µ', 'LABEL_2': '–ü–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω–æ–µ'}
    label = sentiment[0]['label']
    confidence = sentiment[0]['score']
    return labels[label], confidence

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —ç–º–æ—Ü–∏–π
def get_emotion(text):
    result = emotion_model(text, truncation=True, max_length=512)
    translated_label = emotion_labels_map.get(result[0]['label'], result[0]['label'])
    return translated_label, result[0]['score']

# --- Telegram bot ---
API_TOKEN = '7692104667:AAHxWazqOrWLPkgN188jzt0eJ_tyDImgAIk'  # –ó–∞–º–µ–Ω–∏—Ç–µ –Ω–∞ –≤–∞—à —Ç–æ–∫–µ–Ω –æ—Ç @BotFather
bot = telebot.TeleBot(API_TOKEN)

# –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–æ–º–∞–Ω–¥—ã /start
@bot.message_handler(commands=['start'])
def send_welcome(message):
    bot.reply_to(message, "–ü—Ä–∏–≤–µ—Ç! –û—Ç–ø—Ä–∞–≤—å –º–Ω–µ —Ç–µ–∫—Å—Ç, –∏ —è –æ–ø—Ä–µ–¥–µ–ª—é –µ–≥–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—é.")


def save_to_db(user_id, username, text, category, confidence, keywords, emotion, sentiment):
    try:
        conn = sqlite3.connect("bot_messages.db")
        cursor = conn.cursor()
        cursor.execute('''
            INSERT INTO messages (user_id, username, text, predicted_category, confidence, keywords, emotion, sentiment)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?)
        ''', (
            user_id,
            username,
            text,
            category,
            round(float(confidence), 2),
            keywords,
            emotion,  # –°–æ—Ö—Ä–∞–Ω—è–µ–º —ç–º–æ—Ü–∏—é
            sentiment  # –°–æ—Ö—Ä–∞–Ω—è–µ–º –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–µ
        ))
        conn.commit()
        conn.close()
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –¥–∞–Ω–Ω—ã—Ö –≤ –ë–î: {e}")

def get_word_importance(text):
    inputs = tokenizer(text, return_tensors="pt", return_offsets_mapping=True, truncation=True, padding=True, max_length=256)

    embedding_layer = model.get_input_embeddings()
    embedded = embedding_layer(inputs['input_ids'])
    embedded.requires_grad_()
    embedded.retain_grad()

    outputs = model(inputs_embeds=embedded, attention_mask=inputs['attention_mask'])
    pred_class = torch.argmax(outputs.logits, dim=1)
    outputs.logits[0, pred_class].backward()

    grads = embedded.grad[0]
    grads_norm = grads.norm(dim=1)

    tokens = tokenizer.convert_ids_to_tokens(inputs['input_ids'][0])
    offsets = inputs['offset_mapping'][0].tolist()

    word_scores = {}
    current_word = ""
    current_score = 0
    current_len = 0

    for token, offset, score in zip(tokens, offsets, grads_norm):
        if token in ["[CLS]", "[SEP]"]:
            continue
        if token.startswith("##"):
            current_word += token[2:]
            current_score += score.item()
            current_len += 1
        else:
            if current_word:
                word_scores[current_word] = current_score / max(current_len, 1)
            current_word = token
            current_score = score.item()
            current_len = 1

    if current_word:
        word_scores[current_word] = current_score / max(current_len, 1)

    sorted_words = sorted(word_scores.items(), key=lambda x: x[1], reverse=True)

    return sorted_words[:5]

# –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π
@bot.message_handler(func=lambda message: True)
def handle_text(message):
    text = message.text
    try:
        # --- –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞ ---
        class_name, confidence = classify_text(text)
        confidence = round(float(confidence), 2)

        # --- –≠–º–æ—Ü–∏—è —Ç–µ–∫—Å—Ç–∞ ---
        emotion, emotion_confidence = get_emotion(text)

        # --- –ù–∞—Å—Ç—Ä–æ–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ ---
        sentiment, sentiment_confidence = get_sentiment(text)

        # --- –í–∞–∂–Ω—ã–µ —Å–ª–æ–≤–∞ –ø–æ –º–Ω–µ–Ω–∏—é –º–æ–¥–µ–ª–∏ ---
        important_words = get_word_importance(text)
        words_str = ', '.join([word for word, _ in important_words])
        
        # --- –§–æ—Ä–º–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç ---
        response = (
            f"üß† –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω–∞—è –∫–∞—Ç–µ–≥–æ—Ä–∏—è: *{class_name}*\n"
            f"üìä –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: *{confidence:.2%}*\n\n"
            f"üîç –í–∞–∂–Ω—ã–µ —Å–ª–æ–≤–∞ –ø–æ –º–Ω–µ–Ω–∏—é –º–æ–¥–µ–ª–∏:\n"
            f"{words_str}\n\n"
            f"üí≠ –¢–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å —Ç–µ–∫—Å—Ç–∞: *{sentiment}* —Å —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é {sentiment_confidence:.2f}\n"
            f"üòå –≠–º–æ—Ü–∏—è —Ç–µ–∫—Å—Ç–∞: *{emotion}* —Å —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é {emotion_confidence:.2f}\n"
        )

        bot.reply_to(message, response, parse_mode="Markdown")

        # --- –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –ë–î ---
        save_to_db(
            user_id=message.from_user.id,
            username=message.from_user.username or "unknown",
            text=text,
            category=class_name,
            confidence=confidence,
            keywords=words_str,  # –ü–µ—Ä–µ–¥–∞–µ–º –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞
            emotion=emotion,  # –°–æ—Ö—Ä–∞–Ω—è–µ–º —ç–º–æ—Ü–∏—é
            sentiment=sentiment  # –°–æ—Ö—Ä–∞–Ω—è–µ–º –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–µ
        )

    except Exception as e:
        bot.reply_to(message, f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏: {e}")

# –ó–∞–ø—É—Å–∫ –±–æ—Ç–∞
print("–ë–æ—Ç –∑–∞–ø—É—â–µ–Ω.")
bot.infinity_polling()