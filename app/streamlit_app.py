import streamlit as st
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import torch
import numpy as np
from scipy.special import softmax
import pickle
from transformers import pipeline
import sqlite3

# –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –∏ —ç–Ω–∫–æ–¥–µ—Ä–∞
model = AutoModelForSequenceClassification.from_pretrained("./rubert_final_model")
tokenizer = AutoTokenizer.from_pretrained("./rubert_final_model")

with open("rubert_label_encoder.pkl", "rb") as f:
    le = pickle.load(f)

# –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–π
sentiment_model = "sismetanin/rubert-ru-sentiment-rusentiment"
sentiment_analyzer = pipeline("sentiment-analysis", model=sentiment_model)

# –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —ç–º–æ—Ü–∏–π
emotion_model = pipeline(model="seara/rubert-tiny2-ru-go-emotions")
emotion_labels_map = {
    'admiration': '–≤–æ—Å—Ö–∏—â–µ–Ω–∏–µ', 'amusement': '–≤–µ—Å–µ–ª—å–µ', 'anger': '–∑–ª–æ—Å—Ç—å', 'annoyance': '—Ä–∞–∑–¥—Ä–∞–∂–µ–Ω–∏–µ',
    'approval': '–æ–¥–æ–±—Ä–µ–Ω–∏–µ', 'caring': '–∑–∞–±–æ—Ç–∞', 'confusion': '–Ω–µ–ø–æ–Ω–∏–º–∞–Ω–∏–µ', 'curiosity': '–ª—é–±–æ–ø—ã—Ç—Å—Ç–≤–æ',
    'desire': '–∂–µ–ª–∞–Ω–∏–µ', 'disappointment': '—Ä–∞–∑–æ—á–∞—Ä–æ–≤–∞–Ω–∏–µ', 'disapproval': '–Ω–µ–æ–¥–æ–±—Ä–µ–Ω–∏–µ', 'disgust': '–æ—Ç–≤—Ä–∞—â–µ–Ω–∏–µ',
    'embarrassment': '—Å–º—É—â–µ–Ω–∏–µ', 'excitement': '–≤–æ–∑–±—É–∂–¥–µ–Ω–∏–µ', 'fear': '—Å—Ç—Ä–∞—Ö', 'gratitude': '–ø—Ä–∏–∑–Ω–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å',
    'grief': '–≥–æ—Ä–µ', 'joy': '—Ä–∞–¥–æ—Å—Ç—å', 'love': '–ª—é–±–æ–≤—å', 'nervousness': '–Ω–µ—Ä–≤–æ–∑–Ω–æ—Å—Ç—å', 'optimism': '–æ–ø—Ç–∏–º–∏–∑–º',
    'pride': '–≥–æ—Ä–¥–æ—Å—Ç—å', 'realization': '–æ—Å–æ–∑–Ω–∞–Ω–∏–µ', 'relief': '–æ–±–ª–µ–≥—á–µ–Ω–∏–µ', 'remorse': '—Ä–∞—Å–∫–∞—è–Ω–∏–µ',
    'sadness': '–≥—Ä—É—Å—Ç—å', 'surprise': '—É–¥–∏–≤–ª–µ–Ω–∏–µ', 'neutral': '–Ω–µ–π—Ç—Ä–∞–ª—å–Ω–æ—Å—Ç—å'
}

# –§—É–Ω–∫—Ü–∏—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞
def classify_text(text: str):
    # –û–±—Ä–µ–∑–∞–µ–º –≤—Ö–æ–¥–Ω–æ–π —Ç–µ–∫—Å—Ç –¥–æ 512 —Ç–æ–∫–µ–Ω–æ–≤
    inputs = tokenizer(text, return_tensors="pt", truncation=True, padding=True, max_length=512)
    with torch.no_grad():
        outputs = model(**inputs)
    logits = outputs.logits.detach().cpu().numpy()  # –ü–µ—Ä–µ–º–µ—â–∞–µ–º —Ç–µ–Ω–∑–æ—Ä –Ω–∞ CPU, –µ—Å–ª–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω GPU
    probs = softmax(logits, axis=1)
    # –ò–Ω–¥–µ–∫—Å –∫–ª–∞—Å—Å–∞ —Å –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å—é
    pred_idx = np.argmax(probs)
    # –ù–∞–∑–≤–∞–Ω–∏–µ –∫–ª–∞—Å—Å–∞
    class_name = le.inverse_transform([pred_idx])[0]
    # –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏
    confidence = probs[0][pred_idx]
    return class_name, confidence

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–π
def get_sentiment(text):
    sentiment = sentiment_analyzer(text, truncation=True, max_length=512)
    labels = {'LABEL_0': '–û—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω–æ–µ', 'LABEL_1': '–ù–µ–π—Ç—Ä–∞–ª—å–Ω–æ–µ', 'LABEL_2': '–ü–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω–æ–µ'}
    label = sentiment[0]['label']
    confidence = sentiment[0]['score']
    return labels[label], confidence

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —ç–º–æ—Ü–∏–π
def get_emotion(text):
    result = emotion_model(text, truncation=True, max_length=512)
    translated_label = emotion_labels_map.get(result[0]['label'], result[0]['label'])
    return translated_label, result[0]['score']

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –≤–∞–∂–Ω—ã—Ö —Å–ª–æ–≤
def get_word_importance(text):
    inputs = tokenizer(text, return_tensors="pt", return_offsets_mapping=True, truncation=True, padding=True, max_length=256)

    embedding_layer = model.get_input_embeddings()
    embedded = embedding_layer(inputs['input_ids'])
    embedded.requires_grad_()
    embedded.retain_grad()

    outputs = model(inputs_embeds=embedded, attention_mask=inputs['attention_mask'])
    pred_class = torch.argmax(outputs.logits, dim=1)
    outputs.logits[0, pred_class].backward()

    grads = embedded.grad[0]
    grads_norm = grads.norm(dim=1)

    tokens = tokenizer.convert_ids_to_tokens(inputs['input_ids'][0])
    offsets = inputs['offset_mapping'][0].tolist()

    word_scores = {}
    current_word = ""
    current_score = 0
    current_len = 0

    for token, offset, score in zip(tokens, offsets, grads_norm):
        if token in ["[CLS]", "[SEP]"]:
            continue
        if token.startswith("##"):
            current_word += token[2:]
            current_score += score.item()
            current_len += 1
        else:
            if current_word:
                word_scores[current_word] = current_score / max(current_len, 1)
            current_word = token
            current_score = score.item()
            current_len = 1

    if current_word:
        word_scores[current_word] = current_score / max(current_len, 1)

    sorted_words = sorted(word_scores.items(), key=lambda x: x[1], reverse=True)

    return sorted_words[:5]

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —Ç–∞–±–ª–∏—Ü—ã –≤ –ë–î (–µ—Å–ª–∏ –æ–Ω–∞ –µ—â–µ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç)
def create_table():
    try:
        conn = sqlite3.connect("streamlit_messages.db")
        cursor = conn.cursor()

        # –ó–∞–ø—Ä–æ—Å –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —Ç–∞–±–ª–∏—Ü—ã
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS streamlit_messages (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                text TEXT,
                predicted_category TEXT,
                confidence REAL,
                keywords TEXT,
                emotion TEXT,
                sentiment TEXT
            )
        ''')

        conn.commit()
        conn.close()
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ —Ç–∞–±–ª–∏—Ü—ã –≤ –ë–î: {e}")

# –í—ã–∑–æ–≤ —Ñ—É–Ω–∫—Ü–∏–∏ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —Ç–∞–±–ª–∏—Ü—ã
create_table()

# –§—É–Ω–∫—Ü–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤ –ë–î –¥–ª—è Streamlit
def save_to_db(text, category, confidence, keywords, emotion, sentiment):
    try:
        # –ü–æ–¥–∫–ª—é—á–∞–µ–º—Å—è –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö
        conn = sqlite3.connect("streamlit_messages.db")
        cursor = conn.cursor()
        
        # –í—ã–ø–æ–ª–Ω—è–µ–º SQL –∑–∞–ø—Ä–æ—Å –Ω–∞ –≤—Å—Ç–∞–≤–∫—É –¥–∞–Ω–Ω—ã—Ö –≤ —Ç–∞–±–ª–∏—Ü—É
        cursor.execute('''
            INSERT INTO streamlit_messages (text, predicted_category, confidence, keywords, emotion, sentiment)
            VALUES (?, ?, ?, ?, ?, ?)
        ''', (
            text,
            category,
            round(float(confidence), 2),
            keywords,
            emotion,
            sentiment
        ))
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–∑–º–µ–Ω–µ–Ω–∏—è
        conn.commit()
        conn.close()
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –¥–∞–Ω–Ω—ã—Ö –≤ –ë–î: {e}")

# Streamlit –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å
st.title("–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä —Ç–µ–∫—Å—Ç–æ–≤, –∞–Ω–∞–ª–∏–∑ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ –∏ —ç–º–æ—Ü–∏–π")

# –í–≤–æ–¥ —Ç–µ–∫—Å—Ç–∞
input_text = st.text_area("–í–≤–µ–¥–∏—Ç–µ —Ç–µ–∫—Å—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞:", height=200)

if st.button("–ü—Ä–µ–¥—Å–∫–∞–∑–∞—Ç—å"):
    if input_text:
        # –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞
        class_name, confidence = classify_text(input_text)

        # –≠–º–æ—Ü–∏—è —Ç–µ–∫—Å—Ç–∞
        emotion, emotion_confidence = get_emotion(input_text)

        # –ù–∞—Å—Ç—Ä–æ–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞
        sentiment, sentiment_confidence = get_sentiment(input_text)

        # –í–∞–∂–Ω—ã–µ —Å–ª–æ–≤–∞ –ø–æ –º–Ω–µ–Ω–∏—é –º–æ–¥–µ–ª–∏
        important_words = get_word_importance(input_text)
        words_str = ', '.join([word for word, _ in important_words])


        # –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞
        response = (
            f"üß† –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω–∞—è –∫–∞—Ç–µ–≥–æ—Ä–∏—è: *{class_name}*\n"
            f"üìä –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: *{confidence:.2%}*\n\n"
            f"üîç –í–∞–∂–Ω—ã–µ —Å–ª–æ–≤–∞ –ø–æ –º–Ω–µ–Ω–∏—é –º–æ–¥–µ–ª–∏:\n"
            f"{words_str}\n\n"
            f"üí≠ –¢–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å —Ç–µ–∫—Å—Ç–∞: *{sentiment}* —Å —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é {sentiment_confidence:.2f}\n"
            f"üòå –≠–º–æ—Ü–∏—è —Ç–µ–∫—Å—Ç–∞: *{emotion}* —Å —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é {emotion_confidence:.2f}\n"
        )

        st.markdown(response)

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ –≤ –ë–î
        save_to_db(
            text=input_text,
            category=class_name,
            confidence=confidence,
            keywords=words_str,  # –ü–µ—Ä–µ–¥–∞–µ–º –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞
            emotion=emotion,  # –°–æ—Ö—Ä–∞–Ω—è–µ–º —ç–º–æ—Ü–∏—é
            sentiment=sentiment  # –°–æ—Ö—Ä–∞–Ω—è–µ–º –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–µ
        )

    else:
        st.warning("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤–≤–µ–¥–∏—Ç–µ —Ç–µ–∫—Å—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞.")
